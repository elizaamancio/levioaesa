import numpy as np
import pylab as plt


goal = 12

# map cell to cell, add circular cell to goal point

points_list = [(0,1),
(0,3),
(0,6),
(0,15),
(1,0),
(1,2),
(1,3),
(1,4),
(1,6),
(1,11),
(2,0),
(2,1),
(2,6),
(3,0),
(3,1),
(3,4),
(3,6),
(4,3),
(4,6),
(5,8),
(5,10),
(6,0),
(6,1),
(6,2),
(6,3),
(6,4),
(7,0),
(7,5),
(7,6),
(8,10),
(9,11),
(9,12),
(9,13),
(10,5),
(10,8),
(10,9),
(10,11),
(10,12),
(10,13),
(11,12),
(11,13),
(12,11),
(12,13),
(13,9),
(13,11),
(14,8),
(14,9),
(14,10),
(14,11),
(14,12),
(14,13),
(15,7),
(15,9),
(15,11),
#(15,12),
(15,13)
]

# how many points in graph? x points
MATRIX_SIZE = 16


# create matrix x*y
R = np.matrix(np.ones(shape=(MATRIX_SIZE, MATRIX_SIZE)))
R *= -1

# how many points in graph? x points
MATRIX_SIZE = 16


# create matrix x*y
R = np.matrix(np.ones(shape=(MATRIX_SIZE, MATRIX_SIZE)))
R *= -1

R[(0,1)] = 10
R[(0,3)] = 10
R[(0,6)] = 10
#R[(0,15)] = 100
R[(0,15)] = 10
R[(1,0)] = 10
R[(1,2)] = 10
R[(1,3)] = 10
R[(1,4)] = 10
R[(1,6)] = 10
#R[(1,11)] = 100
R[(1,11)] = 10
R[(2,0)] = 10
R[(2,1)] = 10
R[(2,6)] = 10
R[(3,0)] = 10
R[(3,1)] = 10
R[(3,4)] = 10
R[(3,6)] = 10
R[(4,3)] = 10
R[(4,6)] = 10
R[(5,8)] = 10
R[(5,10)] = 10
R[(6,0)] = 10
R[(6,1)] = 10
R[(6,2)] = 10
R[(6,3)] = 10
R[(6,4)] = 10
R[(7,0)] = 10
#R[(7,5)] = 100
R[(7,5)] = 10
R[(7,6)] = 10
#R[(8,10)] = 100
R[(8,15)] = 10
R[(9,11)] = 10
R[(9,12)] = 10
#R[(9,13)] = 100
R[(9,13)] = 10
R[(10,5)] = 10
R[(10,8)] = 10
R[(10,9)] = 10
R[(10,11)] = 10
R[(10,12)] = 10
R[(10,13)] = 10
R[(11,12)] = 10
R[(11,13)] = 10
R[(12,11)] = 10
R[(12,13)] = 10
R[(13,9)] = 10
R[(13,11)] = 10
R[(14,8)] = 10
R[(14,9)] = 10
R[(14,10)] = 10
R[(14,11)] = 10
R[(14,12)] = 10
R[(14,13)] = 10
R[(15,7)] = 10
R[(15,9)] = 10
R[(15,11)] = 10
R[(15,12)] = 10
R[(15,13)] = 10


# assign zeros to paths and 200 to goal-reaching point


for point in points_list:
    print(point)
    if point[1] == goal:
        R[point] = 200

    if point[0] == goal:
        R[point[::-1]] = 200

# add goal point round trip
#R[goal,goal]= 500

print (R)


Q = np.matrix(np.zeros([MATRIX_SIZE,MATRIX_SIZE]))

# learning parameter
gamma = 0.7

initial_state = 0

def available_actions(state):
    current_state_row = R[state,]
    av_act = np.where(current_state_row > 0)[1]
    return av_act

available_act = available_actions(initial_state)

def sample_next_action(available_actions_range):
    next_action = int(np.random.choice(available_act,1))
    return next_action

action = sample_next_action(available_act)

def update(current_state, action, gamma):

  max_index = np.where(Q[action,] == np.max(Q[action,]))[1]

  if max_index.shape[0] > 1:
      max_index = int(np.random.choice(max_index, size = 1))
  else:
      max_index = int(max_index)
  max_value = Q[action, max_index]

  Q[current_state, action] = R[current_state, action] + gamma * max_value
  print('max_value', R[current_state, action] + gamma * max_value)

  if (np.max(Q) > 0):
    return(np.sum(Q/np.max(Q)*100))
  else:
    return (0)

update(initial_state, action, gamma)


# Training
scores = []
for i in range(2000):
    current_state = np.random.randint(0, int(Q.shape[0]))
    available_act = available_actions(current_state)
    action = sample_next_action(available_act)
    score = update(current_state,action,gamma)
    scores.append(score)
    print ('Score:', str(score))

print("Trained Q matrix:")
print(Q/np.max(Q)*100)


# Testing

current_state = 8
print(current_state)
steps = [current_state]
i= 0

while i<9:
    i = i+ 1
    next_step_index = np.where(Q[current_state,] == np.max(Q[current_state,]))[1]

    for j in range(16):
      Q[j, next_step_index] = 0

    if next_step_index.shape[0] > 1:
        next_step_index = int(np.random.choice(next_step_index, size = 1))
    else:
        next_step_index = int(next_step_index)

    steps.append(next_step_index)
    current_state = next_step_index

print("Most efficient path from ")

print(goal)
print(steps)

plt.plot(scores)
plt.show()
